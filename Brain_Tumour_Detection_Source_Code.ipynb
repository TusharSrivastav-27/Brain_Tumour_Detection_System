{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Brain_Tumour_Detection_Source_Code.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1O2YigXkav5jt5PeisguVs3nejpYsuMno","authorship_tag":"ABX9TyND0Tm3JQGxoUYmKMq3Ge1C"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"nQOxTOOiyPmP"},"source":["from keras.applications import vgg16\n","img_rows, img_cols = 224, 224\n","VGG=vgg16.VGG16(weights='imagenet',include_top=False ,input_shape=(img_rows, img_cols,3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zy42MO0i1gl6"},"source":["for layer in VGG.layers:\n","    layer.trainable=False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aoewCllo1lcN"},"source":["def top(bottom_model, num_classes):\n","\n","    top_model = bottom_model.output\n","    top_model = GlobalAveragePooling2D()(top_model)\n","    top_model = Dense(1024,activation='relu')(top_model)\n","    top_model = Dense(512,activation='relu')(top_model)\n","    top_model = Dense(512,activation='relu')(top_model)\n","    top_model = Dense(256,activation='relu')(top_model)\n","    top_model = Dense(128,activation='relu')(top_model)\n","    top_model = Dense(num_classes,activation='softmax')(top_model)\n","    return top_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hqiILm1b1qFP"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.models import Model\n","\n","num_classes = 2\n","\n","FC_Head = top(VGG, num_classes)\n","\n","model = Model(inputs = VGG.input, outputs = FC_Head)\n","\n","print(model.summary())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8-HWAttW1udW"},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_data_dir = '/content/drive/MyDrive/Dataset/Train'\n","validation_data_dir = '/content/drive/MyDrive/Dataset/Validation'\n"," \n","train_datagen = ImageDataGenerator(rescale=1./255)\n"," \n","validation_datagen = ImageDataGenerator(rescale=1./255)\n"," \n","batch_size = 64\n"," \n","train_generator = train_datagen.flow_from_directory(\n","        train_data_dir,\n","        target_size=(img_rows, img_cols),\n","        batch_size=batch_size,\n","        class_mode='binary')\n"," \n","validation_generator = validation_datagen.flow_from_directory(\n","        validation_data_dir,\n","        target_size=(img_rows, img_cols),\n","        batch_size=batch_size,\n","        class_mode='binary')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0jWQTS1S10V3"},"source":["from keras.optimizers import RMSprop\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","                  \n","checkpoint = ModelCheckpoint(\"brain_vgg.h5\",\n","                             monitor=\"val_loss\",\n","                             mode=\"min\",\n","                             save_best_only = True,\n","                             verbose=1)\n","\n","earlystop = EarlyStopping(monitor = 'val_loss', \n","                          min_delta = 0, \n","                          patience = 3,\n","                          verbose = 1,\n","                          restore_best_weights = True)\n","\n","callbacks = [earlystop, checkpoint]\n"," \n","model.compile(loss = 'binary_crossentropy',\n","              optimizer = RMSprop(lr = 0.001),\n","              metrics = ['accuracy'])\n","\n","nb_train_samples = 178\n","nb_validation_samples = 37\n"," \n","epochs = 10\n","batch_size = 64\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch = nb_train_samples // batch_size,\n","    epochs = epochs,\n","    callbacks = callbacks,\n","    validation_data = validation_generator,\n","    validation_steps = nb_validation_samples // batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3uTRdbqq17dF"},"source":["from keras.models import load_model\n","\n","classifier = load_model('/content/drive/My Drive/brain_vgg.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGKbxUt62Acp"},"source":["import os\n","import cv2\n","import numpy as np\n","from os import listdir\n","from os.path import isfile, join\n","from google.colab.patches import cv2_imshow\n","\n","brain_tumour_dict = {\"[0]\": \"Detected\", \n","                     \"[1]\": \"Not detected\"}                \n","\n","brain_tumour_dict_n = {\"Yes\": \"yes\", \n","                        \"No\": \"no\"}\n","\n","def draw_test(name, pred, im):\n","    tumour = brain_tumour_dict[str(pred)]\n","    BLACK = [0,0,0]\n","    expanded_image = cv2.copyMakeBorder(im, 80, 0, 0, 100 ,cv2.BORDER_CONSTANT,value=BLACK)\n","    cv2.putText(expanded_image, tumour, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n","    cv2_imshow(expanded_image)\n","\n","def getRandomImage(path):\n","    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n","    random_directory = np.random.randint(0,len(folders))\n","    path_class = folders[random_directory]\n","    print(\"Class - \" + brain_tumour_dict_n[str(path_class)])\n","    file_path = path + path_class\n","    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n","    random_file_index = np.random.randint(0,len(file_names))\n","    image_name = file_names[random_file_index]\n","    return cv2.imread(file_path+\"/\"+image_name)    \n","\n","for i in range(0,10):\n","    input_im = getRandomImage(\"/content/drive/My Drive/Dataset/Test/\")\n","    input_original = input_im.copy()\n","    input_original = cv2.resize(input_original, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_LINEAR)\n","    \n","    input_im = cv2.resize(input_im, (224, 224), interpolation = cv2.INTER_LINEAR)\n","    input_im = input_im / 255.\n","    input_im = input_im.reshape(1,224,224,3) \n","    \n","    res = np.argmax(classifier.predict(input_im, 1, verbose = 0), axis=1)\n","    \n","    draw_test(\"Prediction\", res, input_original) "],"execution_count":null,"outputs":[]}]}